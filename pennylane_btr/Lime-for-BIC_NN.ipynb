{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 0: DATA LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    cleaned = re.sub(r'<.*?>', '', text).lower()\n",
    "    return cleaned\n",
    "\n",
    "def load_imdb_subset(\n",
    "    num_samples=5000, \n",
    "    min_df=1, \n",
    "    max_features=15, \n",
    "    stopwords_option=True,\n",
    "    stop_words = 'english'\n",
    "):\n",
    "    \n",
    "    data = load_files(\n",
    "        r\"C:/Users/migue/Downloads/aclImdb_v1/aclImdb/train\",\n",
    "        categories=['pos','neg'], \n",
    "        encoding=\"utf-8\", \n",
    "        decode_error=\"replace\"                  \n",
    "    )\n",
    "    X_text_all, y_all = data.data, data.target\n",
    "\n",
    "\n",
    "    X_text_all = [clean_text(txt) for txt in X_text_all]\n",
    "\n",
    "    # Shuffle & truncate to num_samples\n",
    "    full_idx = np.arange(len(X_text_all))\n",
    "    #np.random.shuffle(full_idx)\n",
    "    subset_idx = full_idx[:num_samples]\n",
    "    global X_text \n",
    "    X_text = [X_text_all[i] for i in subset_idx]\n",
    "    y = y_all[subset_idx]\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    # Vectorizer: presence/absence\n",
    "    if stopwords_option:\n",
    "        vectorizer = CountVectorizer(\n",
    "            binary=True, stop_words=stop_words, \n",
    "            min_df=min_df, max_features=max_features\n",
    "        )\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(\n",
    "            binary=True, stop_words='english', \n",
    "            min_df=min_df, max_features=max_features\n",
    "        )\n",
    "\n",
    "    vectorizer.fit(X_train)\n",
    "    return X_train, X_test, y_train, y_test, vectorizer\n",
    "\n",
    "\n",
    "\n",
    "def train_NN_classifier(X_train, y_train, X_test, y_test, vectorizer):\n",
    "    \"\"\"\n",
    "    Trains a neural network on the binary presence/absence of words.\n",
    "    Returns the fitted model.\n",
    "    \"\"\"\n",
    "    X_train_bow = vectorizer.transform(X_train)\n",
    "    X_valid_bow = vectorizer.transform(X_test)\n",
    "    input_dim = X_train_bow.shape[1]\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),  # First hidden layer\n",
    "        Dropout(0.3),  # Dropout with 30% probability\n",
    "        Dense(32, activation='relu'),  # Second hidden layer\n",
    "        Dropout(0.2),  # Dropout with 20% probability\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate = 0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_bow, y_train, epochs=50, batch_size=20, validation_data=(X_valid_bow, y_test), verbose=1, callbacks=[early_stopping])\n",
    "    return model\n",
    "\n",
    "def get_cached_NN(X_train, y_train, vectorizer, num_samples, max_features, stop_words, X_valid, y_valid):\n",
    "\n",
    "    filename = f\"cached_classifier_ns{num_samples}_mf{max_features}_sw{stop_words}_NN_classifier_seed0.pkl\"\n",
    "    if os.path.exists(filename):\n",
    "        print(\"Loading cached logistic from\", filename)\n",
    "        with open(filename, 'rb') as f:\n",
    "            clNN = pickle.load(f)\n",
    "    else:\n",
    "        print(\"No cached classifier found. Training a new one...\")\n",
    "        clNN = train_NN_classifier(X_train, y_train, X_valid, y_valid, vectorizer)\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(clNN, f)\n",
    "        print(\"Cached classifier saved as\", filename)\n",
    "    return clNN\n",
    "\n",
    "def train_NN_classifier_filt(X_train_filt, y_train_filt, X_test_filt, y_test_filt, vectorizer_filt):\n",
    "    \"\"\"\n",
    "    Trains a neural network on the binary presence/absence of words.\n",
    "    Returns the fitted model.\n",
    "    \"\"\"\n",
    "    X_train_bow_filt = vectorizer_filt.transform(X_train_filt)\n",
    "    X_valid_bow_filt = vectorizer_filt.transform(X_test_filt)\n",
    "    input_dim = X_train_bow_filt.shape[1]\n",
    "\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),  # First hidden layer\n",
    "        Dropout(0.3),  # Dropout with 30% probability\n",
    "        Dense(32, activation='relu'),  # Second hidden layer\n",
    "        Dropout(0.2),  # Dropout with 20% probability\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate = 0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_bow_filt, y_train_filt, epochs=50, batch_size=20, validation_data=(X_valid_bow_filt, y_test_filt), verbose=1, callbacks=[early_stopping])\n",
    "    return model\n",
    "\n",
    "def get_cached_NN_filt(X_train_filt, y_train_filt, vectorizer_filt, num_samples, max_features, X_valid_filt, y_valid_filt):\n",
    "    filename = f\"cached_classifier_ns{num_samples}_mf{max_features}_sw_filtered_NN_classifier_seed0.pkl\"\n",
    "    if os.path.exists(filename):\n",
    "        print(\"Loading cached logistic from\", filename)\n",
    "        with open(filename, 'rb') as f:\n",
    "            clNN_filt = pickle.load(f)\n",
    "    else:\n",
    "        print(\"No cached classifier found. Training a new one...\")\n",
    "        clNN_filt = train_NN_classifier_filt(X_train_filt, y_train_filt, X_valid_filt, y_valid_filt, vectorizer_filt)\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(clNN_filt, f)\n",
    "        print(\"Cached classifier saved as\", filename)\n",
    "    return clNN_filt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSICAL LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classical_lime(\n",
    "    text_sample, clNN, vectorizer,  \n",
    "    k_features=20, num_samples=50   \n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs classical LIME on a single text instance.\n",
    "    Returns the top (word, weight) pairs.\n",
    "    \"\"\"\n",
    "    class_names = [\"negative\", \"positive\"]\n",
    "    explainer = LimeTextExplainer(class_names=class_names, feature_selection=\"auto\")\n",
    "\n",
    "    def predict_proba(texts):\n",
    "        bow = vectorizer.transform(texts) \n",
    "        #print('shaspe of box', bow.shape, ', text_sample:',text_sample, 'features: ', k_features, 'samples: ', num_samples)\n",
    "        # print(bow)\n",
    "        proba = clNN.predict(bow.toarray())\n",
    "        if proba.ndim == 1:  # If 1D, reshape to (num_samples, 1)\n",
    "            proba = proba.reshape(-1, 1)\n",
    "        #print('proba', proba, 'dimension', proba.shape, 'return', np.hstack((1 - proba, proba)))\n",
    "        return np.column_stack((1 - proba, proba))  # Return probabilities for both classes\n",
    "        \n",
    "        \n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        text_sample,\n",
    "        predict_proba,\n",
    "        num_features=k_features,\n",
    "        num_samples=num_samples \n",
    "    )\n",
    "    return explanation.as_list() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTAL ROUTINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment( \n",
    "    num_samples=500,\n",
    "    min_df=1,\n",
    "    max_features=20,\n",
    "    \n",
    "    stopwords_option=True,\n",
    "    lime_num_samples=300,\n",
    "    stop_words = 'english',\n",
    "    max_features_filt = 20\n",
    "\n",
    "):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, vectorizer = load_imdb_subset(\n",
    "        num_samples=num_samples,\n",
    "        min_df=min_df,\n",
    "        max_features=max_features,\n",
    "        stopwords_option=stopwords_option,\n",
    "        stop_words = stop_words\n",
    "        )\n",
    "\n",
    "    clNN = get_cached_NN(X_train, y_train, vectorizer, num_samples, max_features, stop_words, X_test, y_test)\n",
    "\n",
    "    X_test_bow = vectorizer.transform(X_test)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    test_acc = accuracy_score(y_test, clNN.predict(X_test_bow) > 0.5)\n",
    "\n",
    "    instance_local_accuracies = []\n",
    "\n",
    "    print(\"Shape of y_train:\", y_train.shape)\n",
    "    print(\"Shape of y_test:\", y_test.shape)\n",
    "    X_all = X_train + X_test \n",
    "    y_all = np.concatenate([y_train, y_test.ravel()])\n",
    "\n",
    "\n",
    "\n",
    "    word_weights_unf = defaultdict(list)\n",
    "\n",
    "    for idx in range(len(X_all)):\n",
    "        text_sample = X_all[idx]\n",
    "        y_true = y_all[idx]\n",
    "\n",
    "\n",
    "        explanation_lime_unfiltered = run_classical_lime(\n",
    "            text_sample, clNN, vectorizer, \n",
    "            k_features=max_features, num_samples=lime_num_samples\n",
    "        )\n",
    "\n",
    "        bow = vectorizer.transform([text_sample])\n",
    "        bin_features = bow.toarray()[0]\n",
    "\n",
    "        contributions_unfiltered_abs = [(word, abs(score)) for word, score in explanation_lime_unfiltered]\n",
    "        \n",
    "        for word, weight in contributions_unfiltered_abs:\n",
    "        \n",
    "            word_weights_unf[word].append(weight)\n",
    "\n",
    "        global_avg_weights_unf = {word: sum(weights) / len(weights) for word, weights in word_weights_unf.items()}\n",
    "\n",
    "        threshold = 0.01\n",
    "        \n",
    "\n",
    "        filtered_words = {word: avg for word, avg in global_avg_weights_unf.items() if avg >= threshold}\n",
    "        rubish_words = {word: avg for word, avg in global_avg_weights_unf.items() if avg <= threshold}\n",
    "        #print(\"filtered_words\", filtered_words)    #There is an issue here, the filtered words are not global, they are local. rubish should also be global\n",
    "\n",
    "    print('filtered_words', filtered_words, 'rubish_words:', rubish_words)\n",
    "    \n",
    "    features_filt = len(global_avg_weights_unf) - len(rubish_words)\n",
    "    \n",
    "    X_train_filt, X_test_filt, y_train_filt, y_test_filt, vectorizer_filt = load_imdb_subset(\n",
    "        num_samples=num_samples,\n",
    "        min_df=min_df,\n",
    "        max_features= max_features,\n",
    "        stopwords_option=stopwords_option,\n",
    "        stop_words = stop_words + list(rubish_words.keys())\n",
    "        )\n",
    "    \n",
    "    # X_train_bow_filt = vectorizer_filt.transform(X_train_filt)\n",
    "    # input_dim = X_train_bow_filt.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "    clNN_filtered = get_cached_NN_filt(X_train_filt, y_train, vectorizer_filt, num_samples, features_filt, X_test_filt, y_test)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # print(\"Shape of training data:\", X_train_filt.shape)\n",
    "    # print(\"Shape of X_test_bow_filt:\", X_test_bow_filt.shape)\n",
    "    # print(\"Shape expected by model:\", clNN_filtered.input_shape)\n",
    "    # print(\"Shape of y_test_filt:\", y_test_filt.shape)\n",
    "    # print(\"Shape of predictions:\", clNN_filtered.predict(X_test_bow_filt.toarray()).shape)\n",
    "    # print(\"Model summary:\")\n",
    "    # clNN_filtered.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_all_filt = X_train_filt + X_test_filt\n",
    "    for idx in range(len(X_all_filt)):\n",
    "\n",
    "        text_sample_filt = X_all_filt[idx]\n",
    "\n",
    "        explanation_lime_filtered = run_classical_lime(\n",
    "            text_sample_filt, clNN_filtered, vectorizer_filt, \n",
    "            k_features=features_filt, num_samples=lime_num_samples\n",
    "        )\n",
    "        \n",
    "        bow_filt = vectorizer_filt.transform([text_sample_filt])\n",
    "\n",
    "        y_pred = clNN_filtered.predict(bow_filt.toarray())[0].item()\n",
    "        y_pred_label = 1 if y_pred >= 0.5 else 0\n",
    "\n",
    "        instance_accuracy = int(y_pred_label == y_true)\n",
    "        #print(\"instance_accuracy:\", instance_accuracy)\n",
    "        instance_local_accuracies.append(instance_accuracy)\n",
    "\n",
    "        contributions_filtered_abs = [(word, abs(score)) for word, score in explanation_lime_filtered]\n",
    "        \n",
    "        #print(\"idx\", idx, \"text sample\", text_sample)\n",
    "     \n",
    "        word_weights = defaultdict(list)\n",
    "\n",
    "        for word, weight in contributions_filtered_abs:\n",
    "            word_weights[word].append(weight)\n",
    "\n",
    "        \n",
    "    X_test_bow_filt = vectorizer.transform(X_test_filt)\n",
    "    test_acc_filt = accuracy_score(y_test_filt, clNN_filtered.predict(X_test_bow_filt.toarray()) > 0.5)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    results = {\n",
    "        \"num_unf_words\": len(word_weights_unf),\n",
    "        \"num_filt_words\": len(word_weights),\n",
    "        \"local_accuracy\": np.mean(instance_local_accuracies),\n",
    "        \"global_acc\": np.mean(test_acc),\n",
    "        \"global_acc_filtered\": np.mean(test_acc_filt),\n",
    "\n",
    "        #\"words_to_filter\": rubish_words\n",
    "    }\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "Running experiment with: num_samples=200, max_features=15, stopwords=True, lime_num_samples=30, stop_words=['english'],\n",
      "No cached classifier found. Training a new one...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\migue\\miniconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.5227 - loss: 0.6988 - val_accuracy: 0.7000 - val_loss: 0.6747\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4312 - loss: 0.7106 - val_accuracy: 0.7000 - val_loss: 0.6753\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5089 - loss: 0.7006 - val_accuracy: 0.7000 - val_loss: 0.6754\n",
      "Cached classifier saved as cached_classifier_ns200_mf15_sw['english']_NN_classifier_seed0.pkl\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "Shape of y_train: (160,)\n",
      "Shape of y_test: (40, 1)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "filtered_words {np.str_('to'): 0.010212550816191629, np.str_('lot'): 0.014496668475431716, np.str_('painfully'): 0.010527457124416058, np.str_('the'): 0.012468209396752179, np.str_('on'): 0.014783213937233829, np.str_('but'): 0.015768782655794046, np.str_('script'): 0.011192906783950851, np.str_('is'): 0.017176840239853202, np.str_('in'): 0.011773275216821243, np.str_('same'): 0.016163319511294797, np.str_('for'): 0.012758671815082202, np.str_('this'): 0.011826334802699276, np.str_('european'): 0.016297011787934752, np.str_('strong'): 0.01082328698434891, np.str_('he'): 0.011757252768388675, np.str_('baked'): 0.010402712884894699, np.str_('scariest'): 0.015856943009452607, np.str_('risk'): 0.013656996393638616, np.str_('fuel'): 0.011361731576724135, np.str_('that'): 0.010126070423340681, np.str_('hour'): 0.013132570867780186, np.str_('issues'): 0.0103632885164395, np.str_('better'): 0.012475492178354941, np.str_('3'): 0.01271737148867962, np.str_('know'): 0.010675331312758813, np.str_('looking'): 0.014479220572994488, np.str_('of'): 0.011129647755715434, np.str_('modern'): 0.021826463935749, np.str_('den'): 0.014473396133299366, np.str_('back'): 0.011340163515060947, np.str_('baby'): 0.011540482550249724, np.str_('huge'): 0.013307995493238037, np.str_('movie'): 0.010130221632697493, np.str_('maker'): 0.015142262544928165, np.str_('niece'): 0.011401162832999948, np.str_('supporting'): 0.010925582244471807, np.str_('einstein'): 0.01031235671948349, np.str_('by'): 0.010818117570302814, np.str_('where'): 0.010141833250184747, np.str_('person'): 0.016583507722174998, np.str_('none'): 0.01191886282052275, np.str_('family'): 0.020691943432081663, np.str_('girl'): 0.01285963177271146, np.str_('her'): 0.012517772650127065, np.str_('stories'): 0.010804762636850445, np.str_('example'): 0.012713182228614752, np.str_('like'): 0.011054200966864191, np.str_('thanks'): 0.02043652360719327, np.str_('episode'): 0.011893365401959191, np.str_('than'): 0.014517620956844154, np.str_('mr'): 0.010971803820382054, np.str_('10'): 0.012383902843395534, np.str_('with'): 0.012246398293927707, np.str_('us'): 0.010651126331912036, np.str_('ending'): 0.012161060904607843, np.str_('question'): 0.010002986971554861, np.str_('no'): 0.010683451527736788, np.str_('quite'): 0.010180265095810007, np.str_('how'): 0.011361514408443267, np.str_('avoiding'): 0.010510206565195601, np.str_('known'): 0.010232845551280964, np.str_('pretentious'): 0.01584835942824969, np.str_('memories'): 0.012520105454424665, np.str_('off'): 0.01221956438468764, np.str_('didn'): 0.010777971163915873, np.str_('together'): 0.011994997357757385, np.str_('she'): 0.018088940231559023, np.str_('even'): 0.01007496959521412, np.str_('legged'): 0.012075293945960313, np.str_('sixties'): 0.018488154367058765, np.str_('swinging'): 0.011225014931885961, np.str_('broken'): 0.019688359237213474, np.str_('sabrina'): 0.011841800764946344, np.str_('many'): 0.013759077431231434, np.str_('paired'): 0.014461507084877784, np.str_('stating'): 0.01377255540779152, np.str_('nomination'): 0.013404008279288924, np.str_('video'): 0.010731355087988908, np.str_('hysterical'): 0.01256348817308074, np.str_('lost'): 0.012867833271695907, np.str_('five'): 0.01872770492777983, np.str_('factor'): 0.01038281768813612, np.str_('niels'): 0.017159894894586983, np.str_('fired'): 0.015125914919775316, np.str_('performances'): 0.01244621582201796, np.str_('usually'): 0.010959544329005977, np.str_('both'): 0.010384937808050053, np.str_('robson'): 0.010407850490927767, np.str_('roles'): 0.01681550374986299, np.str_('sweat'): 0.013410845119751743, np.str_('does'): 0.011386122758823761, np.str_('around'): 0.011409080747492575, np.str_('wonderland'): 0.015263334950862174, np.str_('disjointed'): 0.010007991822388363, np.str_('enjoyable'): 0.011720514854936399, np.str_('after'): 0.010391220023332764, np.str_('through'): 0.012869080506138244, np.str_('can'): 0.011825169976607574, np.str_('obsessed'): 0.011625558545059247, np.str_('genitalia'): 0.010500949409286028, np.str_('read'): 0.013195609468445437, np.str_('t'): 0.010128309080169625, np.str_('definitely'): 0.013476706875362602, np.str_('frightening'): 0.0162235794937988, np.str_('3d'): 0.015794999198890578, np.str_('length'): 0.012597076943026501, np.str_('life'): 0.012495494133653627, np.str_('murder'): 0.02264174893806687, np.str_('imagination'): 0.017337806252367388, np.str_('pushing'): 0.011520779681160775, np.str_('designed'): 0.01075026929352245, np.str_('people'): 0.011911318451895584, np.str_('originality'): 0.010662609584001809, np.str_('crowd'): 0.011416350936430352, np.str_('genius'): 0.010292389908263326, np.str_('diaz'): 0.015559187020496074, np.str_('one'): 0.010132182505444181, np.str_('came'): 0.010001004642864434, np.str_('romance'): 0.010007856157749044, np.str_('result'): 0.014613546491798433, np.str_('making'): 0.013571896588675724, np.str_('stoneface'): 0.014778716136010535, np.str_('motions'): 0.01163071637986929, np.str_('bother'): 0.012570024334013942, np.str_('regardless'): 0.01009698914365526, np.str_('wolf'): 0.016252781671199434, np.str_('house'): 0.013616548178764384, np.str_('twice'): 0.010312728835103872, np.str_('changed'): 0.011518128646944632, np.str_('hadn'): 0.017474013384756064, np.str_('especially'): 0.010888159476651492, np.str_('compare'): 0.010192680798769609, np.str_('his'): 0.01062758431996111, np.str_('girlfriend'): 0.014116804148348157, np.str_('kill'): 0.013162839496417241, np.str_('robot'): 0.010534876536728901, np.str_('each'): 0.011103865959487612, np.str_('looses'): 0.02211082692601324, np.str_('biggest'): 0.015856855652975153, np.str_('bemoaned'): 0.012303065645747789, np.str_('chip'): 0.012288905917243515, np.str_('expecting'): 0.013651424982545632, np.str_('genie'): 0.014103891240914592, np.str_('someone'): 0.010726587664102852, np.str_('would'): 0.010203309704063412, np.str_('entertaining'): 0.012744102416720159, np.str_('innocence'): 0.024391046691144176, np.str_('taking'): 0.018863778792310097, np.str_('led'): 0.014194178350815536, np.str_('quality'): 0.011291790635034469, np.str_('d'): 0.012339538322276631, np.str_('secret'): 0.0129047224047285, np.str_('sentinel'): 0.010708009476439987, np.str_('katherine'): 0.011661454864245059, np.str_('front'): 0.017114528700756543, np.str_('bloody'): 0.016063200917289303, np.str_('contrived'): 0.012661491547475017, np.str_('jennifer'): 0.01053326331230661, np.str_('heroine'): 0.010527626472012913, np.str_('things'): 0.017989712524178976, np.str_('aimlessly'): 0.01072630041431336, np.str_('music'): 0.013208289894960912, np.str_('dah'): 0.011718080691817036, np.str_('dump'): 0.011298871200459725, np.str_('please'): 0.010958565739741218, np.str_('govinda'): 0.01908112407660084, np.str_('dhawan'): 0.018871763467054017, np.str_('amitabh'): 0.016841704360917115, np.str_('may'): 0.012523039546084623, np.str_('totally'): 0.010858478506033928, np.str_('masala'): 0.0100769703818754, np.str_('songs'): 0.01007076942403961, np.str_('utter'): 0.014941325209238056, np.str_('disgusting'): 0.013459219268636219, np.str_('basically'): 0.010153137649041768, np.str_('other'): 0.010100155998095274, np.str_('jim'): 0.014968799166353148, np.str_('franklin'): 0.011852672218925603, np.str_('implementation'): 0.011766713602407282, np.str_('original'): 0.012122712176084433, np.str_('bakshi'): 0.010531623296478953, np.str_('overall'): 0.0115055100349512, np.str_('backdrops'): 0.016979190964762175, np.str_('unfortunately'): 0.01773431261639282, np.str_('endorse'): 0.01442226099094246, np.str_('nelson'): 0.019489880368357956, np.str_('accuses'): 0.01586193826332218, np.str_('word'): 0.010844672570079735, np.str_('woody'): 0.010139403109910747, np.str_('teaming'): 0.01775062774518242, np.str_('america'): 0.015288125225425038, np.str_('confess'): 0.011868922218171074, np.str_('conjured'): 0.010377960915610203, np.str_('should'): 0.01045956701828239, np.str_('do'): 0.016179640022856993, np.str_('moments'): 0.014001130270469028, np.str_('seem'): 0.015225813852008383, np.str_('alone'): 0.012344015367031043, np.str_('nearly'): 0.01144116056824159, np.str_('higher'): 0.010693795866065873, np.str_('moonstruck'): 0.010311463294586837, np.str_('conceits'): 0.01661609667519378, np.str_('far'): 0.010027325304761607, np.str_('superior'): 0.011807145491809565, np.str_('christmanish'): 0.014640683836208746, np.str_('love'): 0.010696612231369826, np.str_('despite'): 0.01438526925498428, np.str_('son'): 0.01637943501772375, np.str_('soap'): 0.01512968121776282, np.str_('found'): 0.011728069196164322, np.str_('hoped'): 0.014009301612366097, np.str_('til'): 0.02072956656430988, np.str_('looks'): 0.018618161583581594, np.str_('theme'): 0.011870046358502154, np.str_('filmmakers'): 0.010168961884490546, np.str_('wildfire'): 0.02175597733660423, np.str_('indeed'): 0.01348110118908554, np.str_('richness'): 0.012044416243875205, np.str_('panda'): 0.012006665246386264, np.str_('enters'): 0.014643030743728289, np.str_('levels'): 0.01382656388303867, np.str_('platform'): 0.011767492055435338, np.str_('aired'): 0.010587629260239527, np.str_('arden'): 0.015089633184369752, np.str_('awkward'): 0.013225610395155603, np.str_('svendsen'): 0.010568162744750092, np.str_('subplot'): 0.010452296853416419, np.str_('italian'): 0.020981834766897977, np.str_('reality'): 0.011191614353452846, np.str_('directed'): 0.01596305253420709, np.str_('likes'): 0.015313721375700008, np.str_('vidor'): 0.013514955478073134, np.str_('bess'): 0.013460561653041214, np.str_('cannot'): 0.014692370850756135, np.str_('candy'): 0.017691404411873942, np.str_('films'): 0.013064553609430292, np.str_('morphine'): 0.012546751407917223, np.str_('viewers'): 0.011843015033839182, np.str_('momentum'): 0.015159925897176602, np.str_('interpretation'): 0.018172547253907045, np.str_('down'): 0.015307398897253665, np.str_('murray'): 0.012227507044857604, np.str_('sometimes'): 0.011282810259580533, np.str_('saying'): 0.01928036375553369, np.str_('stood'): 0.015389585410350202, np.str_('retrieve'): 0.018774700693794933, np.str_('mouth'): 0.016507045166948238, np.str_('bug'): 0.010369029106553048, np.str_('robbed'): 0.012115278443310753, np.str_('man'): 0.0112448308844084, np.str_('wonderful'): 0.015283902361265492, np.str_('franz'): 0.013502877844181568, np.str_('piece'): 0.013435853104887242, np.str_('fourth'): 0.022489864000815152, np.str_('normal'): 0.012478852070550224, np.str_('level'): 0.018112471041615147, np.str_('dye'): 0.015780764913570104, np.str_('spaceship'): 0.011761886302792509, np.str_('others'): 0.014901565636836103, np.str_('put'): 0.010685329713172698, np.str_('never'): 0.01092669502507998, np.str_('favour'): 0.029577947116063423, np.str_('shifting'): 0.015313869764945035, np.str_('learned'): 0.01428177851330445, np.str_('incredible'): 0.014010549953861934, np.str_('hijacking'): 0.01965493340597882, np.str_('holes'): 0.01649771870061216, np.str_('train'): 0.01022788267896128, np.str_('creates'): 0.014040955290821142, np.str_('veteran'): 0.012647552790562636, np.str_('new'): 0.01623768375521143, np.str_('total'): 0.014697482472423834, np.str_('lake'): 0.011362764630841878, np.str_('amusing'): 0.01840656880534583, np.str_('television'): 0.012583132078142193, np.str_('rada'): 0.010829109968127535, np.str_('senses'): 0.016987264648087405, np.str_('heads'): 0.01081638041685255, np.str_('right'): 0.015812204771714987, np.str_('thought'): 0.012202168473093897, np.str_('coloring'): 0.011891273331319147, np.str_('fact'): 0.011110554951372077, np.str_('paying'): 0.010160974558327172, np.str_('woman'): 0.011553863158085372, np.str_('pass'): 0.011972800371053478, np.str_('captured'): 0.012568948810089589, np.str_('comes'): 0.011278136005588807, np.str_('required'): 0.019558015653455274, np.str_('ages'): 0.013774947132766693, np.str_('decent'): 0.012533100135523573, np.str_('cesspool'): 0.015574682472740502, np.str_('week'): 0.012889516575610943, np.str_('finds'): 0.015305867768851426, np.str_('unlike'): 0.014862763773623371, np.str_('mentioned'): 0.01106863210434438, np.str_('called'): 0.015064234046458133, np.str_('cg'): 0.015022122327758123, np.str_('already'): 0.014509788141847009, np.str_('hear'): 0.014210190970083846, np.str_('ends'): 0.013587795012081903, np.str_('almost'): 0.01174845341003254, np.str_('saber'): 0.011530682867952297, np.str_('revolution'): 0.011485495926077352, np.str_('understated'): 0.01076528640654741, np.str_('ideas'): 0.011346664440396155, np.str_('homeless'): 0.010923120486279074, np.str_('lives'): 0.015537410070655483, np.str_('sgcc'): 0.012342704528721429, np.str_('hope'): 0.012731348861665841, np.str_('grady'): 0.014108840550798599, np.str_('return'): 0.012339810821436837, np.str_('bela'): 0.011029100181360498, np.str_('couldn'): 0.013510994263562854, np.str_('jane'): 0.013219643284888484, np.str_('heavily'): 0.013744959728453982, np.str_('crime'): 0.011518194675512404, np.str_('make'): 0.010247040057883992, np.str_('witted'): 0.013732110051743632, np.str_('executed'): 0.012788707250198999, np.str_('holds'): 0.010705448267027363, np.str_('haven'): 0.018755206016677777, np.str_('holding'): 0.01499080828503101, np.str_('australia'): 0.011036720092300114, np.str_('success'): 0.01578346295306265, np.str_('art'): 0.010927495998853782, np.str_('job'): 0.010632432620611755, np.str_('bit'): 0.01730325411961912, np.str_('late'): 0.01189638054427222, np.str_('ann'): 0.017691888632237456, np.str_('shining'): 0.010999093853643031, np.str_('ronald'): 0.010596217863049514, np.str_('producers'): 0.015299198783531932, np.str_('reflect'): 0.010766836974146087, np.str_('attractive'): 0.010404738243453717, np.str_('whereas'): 0.016128692199898056, np.str_('understand'): 0.011762003678301804, np.str_('adult'): 0.011602143159523261, np.str_('insulting'): 0.017004122879930774, np.str_('industry'): 0.01319415293488737, np.str_('legitimately'): 0.013027291524583432, np.str_('storyline'): 0.012545767801425136, np.str_('rest'): 0.012431896286839779, np.str_('individually'): 0.011453243602332465, np.str_('beaten'): 0.010372977193538474, np.str_('richard'): 0.013137366105463637, np.str_('roof'): 0.010332339510406772, np.str_('rocket'): 0.014061372604171776, np.str_('successful'): 0.010895402598657742, np.str_('less'): 0.012229796532874024, np.str_('recognition'): 0.011879719594139141, np.str_('innocent'): 0.01054472319000798, np.str_('center'): 0.018761079743543706, np.str_('dad'): 0.015147733521400338, np.str_('e'): 0.014142515409397866, np.str_('stopped'): 0.01176431440745054, np.str_('sucks'): 0.02320648772190573, np.str_('ton'): 0.010011817099522221, np.str_('enthusiastic'): 0.018103397460195746, np.str_('outstay'): 0.014195522383956004, np.str_('terrible'): 0.01177975097502688, np.str_('editing'): 0.013704848001999234, np.str_('species'): 0.013629382599562336, np.str_('ilk'): 0.013600284576972184, np.str_('smart'): 0.010666266935583825, np.str_('fascination'): 0.010236059107870142, np.str_('panahi'): 0.012785315330215732, np.str_('depicting'): 0.012386184497306146, np.str_('teddy'): 0.015226201657093642, np.str_('disappointed'): 0.015761985122120882, np.str_('scene'): 0.019160796980313262, np.str_('muddled'): 0.011639063444537995, np.str_('reference'): 0.012050854298451118, np.str_('lakhan'): 0.010589835583097196, np.str_('shows'): 0.019880260951309747, np.str_('agree'): 0.015012122359909966, np.str_('granted'): 0.01102034955001466, np.str_('point'): 0.01058476881796428, np.str_('ways'): 0.01684056010612888, np.str_('stand'): 0.010639523861655679, np.str_('big'): 0.010800117122764468, np.str_('were'): 0.012720143149141452, np.str_('distasteful'): 0.012693759609085958, np.str_('meetings'): 0.01999301609011288, np.str_('drafted'): 0.016813675504820155, np.str_('matrix'): 0.02134655020858517, np.str_('grand'): 0.015065655656571435, np.str_('state'): 0.012020646287034921, np.str_('fluff'): 0.010342367015277942, np.str_('uglier'): 0.015709525524446686, np.str_('noticed'): 0.023832652511234922, np.str_('admiral'): 0.019458347624606093, np.str_('further'): 0.015838133622195907, np.str_('headroom'): 0.013255010902412939, np.str_('gang'): 0.01488647742872748, np.str_('includes'): 0.015115506665506432, np.str_('nod'): 0.013422789101058086, np.str_('soundtracks'): 0.011978949575339275, np.str_('happy'): 0.010620707150358396, np.str_('hurt'): 0.01354510514715411, np.str_('series'): 0.01036121188969727, np.str_('beneath'): 0.014782228484005296, np.str_('dark'): 0.01441134638799431, np.str_('near'): 0.013248176482860271, np.str_('spoof'): 0.01367834949026511, np.str_('porn'): 0.013340386337830901, np.str_('surprisingly'): 0.015504482901818486, np.str_('gordon'): 0.011327358279368762, np.str_('having'): 0.010142939972212163, np.str_('needless'): 0.016116201767600605, np.str_('sans'): 0.014322108646433187, np.str_('doubt'): 0.010793863354223684, np.str_('beautiful'): 0.014149058482304877, np.str_('breasts'): 0.01034349015098662, np.str_('beings'): 0.011706390339724964, np.str_('last'): 0.022761960450734454, np.str_('hill'): 0.017012547936719986, np.str_('pad'): 0.01659716343094441, np.str_('saving'): 0.01595615179391053, np.str_('lathered'): 0.01354767577339549, np.str_('illusions'): 0.012055271686508074, np.str_('attempted'): 0.011367915382538382, np.str_('stereo'): 0.010212221027842043, np.str_('editor'): 0.011651189614560919, np.str_('shoot'): 0.016257975618700484, np.str_('serves'): 0.012575992327299222, np.str_('important'): 0.011718016877930202, np.str_('three'): 0.011247488660574807, np.str_('amazing'): 0.010318581911798215, np.str_('kept'): 0.011950101497419478, np.str_('red'): 0.011699871445954668, np.str_('bullying'): 0.010089500798519169, np.str_('fish'): 0.01598569222333002, np.str_('day'): 0.015333551854255655, np.str_('assumption'): 0.01402746149569602, np.str_('scientist'): 0.013430451294919153, np.str_('colour'): 0.016851617012184274, np.str_('frustration'): 0.011252456188362663, np.str_('milks'): 0.010812385249198147, np.str_('non'): 0.014726915542311234, np.str_('approved'): 0.021838661014708924, np.str_('congratulate'): 0.018244031173951902, np.str_('combination'): 0.02275315569213982, np.str_('spano'): 0.015796761037263553, np.str_('jinks'): 0.011015744346973066, np.str_('defense'): 0.013090535732644862, np.str_('fantasy'): 0.010577856773497662, np.str_('cheap'): 0.011072867594140626, np.str_('ecstacy'): 0.0145400156036575, np.str_('stuff'): 0.010852344349268675, np.str_('suceed'): 0.010163416611783858, np.str_('mash'): 0.026688327431554398, np.str_('c'): 0.012166137732742872, np.str_('offensively'): 0.010570555366168813, np.str_('cry'): 0.0110927648925271, np.str_('reminiscant'): 0.014863441679715346, np.str_('imitation'): 0.014204867763542656, np.str_('disgust'): 0.013930545066934629, np.str_('terms'): 0.010774854322461582, np.str_('mood'): 0.017111919150347512, np.str_('brings'): 0.015389611402986404, np.str_('marriage'): 0.014651641308122096, np.str_('opening'): 0.01366777948336313, np.str_('immaculate'): 0.010490306889706397, np.str_('mouthed'): 0.016927944434773027, np.str_('historical'): 0.016817609380360917, np.str_('highest'): 0.014290261999882288, np.str_('crash'): 0.011479483380557178, np.str_('overtly'): 0.011354281885636457, np.str_('uniformly'): 0.012737651680288226, np.str_('forget'): 0.01226089002020877, np.str_('particularly'): 0.012199816564255228, np.str_('situation'): 0.011758958772771147, np.str_('cursing'): 0.011085103276662648, np.str_('yet'): 0.010863316488915763} rubish_words: {np.str_('damn'): 0.008134092183974574, np.str_('positive'): 0.007984849762831935, np.str_('involving'): 0.0065246328372997155, np.str_('it'): 0.00947045292417845, np.str_('flick'): 0.005918896343088992, np.str_('oh'): 0.0021207741189543765, np.str_('absolutely'): 0.002909613273845717, np.str_('re'): 0.0042635171749823425, np.str_('an'): 0.00902929509534464, np.str_('friend'): 0.009410960912546947, np.str_('over'): 0.0067747247591199876, np.str_('nothing'): 0.007042173378071302, np.str_('so'): 0.009774583686336283, np.str_('lived'): 0.004958567647322261, np.str_('raised'): 0.0029596661457839866, np.str_('color'): 9.358239794079349e-05, np.str_('matter'): 5.9162217750760484e-05, np.str_('different'): 0.007087779321112294, np.str_('then'): 0.008622805503933928, np.str_('care'): 0.009731798922749212, np.str_('half'): 0.008687003116562057, np.str_('seat'): 0.0057916040846969575, np.str_('tourist'): 0.004172046440571708, np.str_('now'): 0.00401325481026113, np.str_('term'): 0.002419516901758105, np.str_('square'): 2.38565053235018e-05, np.str_('not'): 0.0073582607103135625, np.str_('earth'): 0.00999938612676796, np.str_('running'): 0.00990022243898615, np.str_('without'): 0.009701426255048337, np.str_('problem'): 0.008221392715693167, np.str_('seconds'): 0.008849465419054136, np.str_('possible'): 0.0088593490699062, np.str_('lunar'): 0.004155650144633542, np.str_('you'): 0.008988500105764154, np.str_('fatal'): 0.003234220974878865, np.str_('enjoy'): 0.009928060906736341, np.str_('emotion'): 0.00861361796373668, np.str_('watch'): 0.007663500362884487, np.str_('easy'): 0.00811863757450084, np.str_('done'): 0.008463468779749185, np.str_('direction'): 0.0017841830403921219, np.str_('ever'): 0.0057774802691937036, np.str_('don'): 0.004868859685464728, np.str_('chronicles'): 0.009064419796369662, np.str_('great'): 0.00924965529080424, np.str_('all'): 0.0077118144386592, np.str_('kudos'): 0.00695451460940482, np.str_('m'): 0.0059364716418240536, np.str_('spoil'): 0.0043493026408326346, np.str_('who'): 0.009521506238843826, np.str_('infiltrate'): 0.006929545647232476, np.str_('climbing'): 0.006260458947753793, np.str_('pregnant'): 0.004385782863923131, np.str_('are'): 0.008422311631081415, np.str_('explained'): 0.0032659295757218616, np.str_('iron'): 0.0007410494394896291, np.str_('played'): 0.00858822938738112, np.str_('recognized'): 0.008901974845256382, np.str_('major'): 0.006265224796437826, np.str_('a'): 0.00876887138398989, np.str_('feel'): 0.005586359516252155, np.str_('meg'): 0.0006400648175291987, np.str_('when'): 0.007577161883151727, np.str_('and'): 0.009466800243224811, np.str_('any'): 0.009348127824962398, np.str_('characters'): 0.007822808209829592, np.str_('doesn'): 0.007901427077758448, np.str_('did'): 0.008861531152479259, np.str_('time'): 0.007870236043490688, np.str_('anne'): 0.006973034870130003, np.str_('unbearable'): 0.005258734949860214, np.str_('seems'): 0.0075372811344813825, np.str_('keep'): 0.004008948072656644, np.str_('fall'): 0.0007061012005927722, np.str_('s'): 0.008097234222355929, np.str_('recent'): 0.007834680559656528, np.str_('look'): 0.007292413200643448, np.str_('simple'): 0.003500664585101213, np.str_('body'): 0.0006771684640542283, np.str_('out'): 0.0077702253721809444, np.str_('china'): 0.009568718449422406, np.str_('seen'): 0.008498415304343638, np.str_('portrays'): 0.0062653531490978595, np.str_('be'): 0.00902094598029073, np.str_('although'): 0.008086535998863833, np.str_('four'): 0.0037255965584086586, np.str_('residents'): 0.005125025832740474, np.str_('describes'): 0.00030977051798316353, np.str_('from'): 0.00687044420350378, np.str_('type'): 0.007776048171546227, np.str_('integral'): 0.007059669008224722, np.str_('wasted'): 0.006577617862748459, np.str_('blowing'): 0.0034934104668935704, np.str_('talk'): 0.003084652490192805, np.str_('actors'): 0.00636511485044533, np.str_('i'): 0.007458609191904582, np.str_('jimmy'): 0.008109937994355523, np.str_('had'): 0.0057525758212028655, np.str_('alcs'): 0.0024710397627761877, np.str_('year'): 0.0097981735592285, np.str_('movies'): 0.004107730292544985, np.str_('some'): 0.009175141566756959, np.str_('or'): 0.005678134008514509, np.str_('colourful'): 0.004852099677948858, np.str_('beginning'): 0.004170051990274433, np.str_('necessary'): 0.0028623252730175237, np.str_('scenes'): 0.008037829287130814, np.str_('proper'): 0.004287996406539814, np.str_('peters'): 0.003710085129165782, np.str_('suggests'): 0.0030769199224055105, np.str_('sacrificing'): 0.009162605384595325, np.str_('composure'): 0.001897770301579778, np.str_('element'): 0.0011101060870785254, np.str_('screenwriter'): 0.009531659953142466, np.str_('35'): 0.009784066036113842, np.str_('was'): 0.009304479644568039, np.str_('redefining'): 0.007768958053833833, np.str_('taste'): 0.0070959942983612485, np.str_('nino'): 0.006226633966591931, np.str_('its'): 0.006451391927436373, np.str_('film'): 0.00695613954806465, np.str_('at'): 0.009359281789373166, np.str_('end'): 0.005151127235544292, np.str_('bob'): 0.0067925327755989605, np.str_('dean'): 0.005215464874014222, np.str_('what'): 0.007017881075629838, np.str_('watching'): 0.005958138703793307, np.str_('fun'): 0.009989692308119566, np.str_('seven'): 0.007350333106426867, np.str_('adventurous'): 0.006905748640450831, np.str_('because'): 0.009376603710396425, np.str_('diverse'): 0.004121180317472905, np.str_('funny'): 0.007474473336788929, np.str_('see'): 0.009429878529633437, np.str_('performance'): 0.007098172396783347, np.str_('win'): 0.006662286373615238, np.str_('won'): 0.0004286893114857784, np.str_('course'): 0.00934839728716628, np.str_('using'): 0.00870766882965937, np.str_('third'): 0.006908611416313389, np.str_('really'): 0.007843432900116276, np.str_('pantsuit'): 0.005681346654312418, np.str_('everything'): 0.0038272460765680348, np.str_('gere'): 0.008634691597054387, np.str_('give'): 0.00631179373236479, np.str_('two'): 0.006295475871466682, np.str_('their'): 0.00421872168766016, np.str_('acted'): 0.008629296609884377, np.str_('unhappiness'): 0.0075929750194181555, np.str_('glasgow'): 0.0069543323417972465, np.str_('always'): 0.0060222389721084416, np.str_('daddy'): 0.003792341759298859, np.str_('there'): 0.007145918659041393, np.str_('burstyn'): 0.0043572328534238975, np.str_('houston'): 0.007936321493772387, np.str_('rights'): 0.005753722537519794, np.str_('them'): 0.006205452395902392, np.str_('saldana'): 0.003457180069431663, np.str_('tainos'): 0.0031176012078110516, np.str_('fed'): 0.008088186150441922, np.str_('either'): 0.0015037534639485487, np.str_('appreciate'): 0.00937036227981847, np.str_('close'): 0.009350865544612594, np.str_('gritty'): 0.009059368245340725, np.str_('viewer'): 0.009041261116082697, np.str_('val'): 0.006715763331594619, np.str_('pulp'): 0.006212831862964093, np.str_('cast'): 0.009383750655549184, np.str_('screaming'): 0.009815765347185373, np.str_('later'): 0.009470263828844326, np.str_('flip'): 0.008533071514186932, np.str_('as'): 0.00878999803607976, np.str_('exercise'): 0.006638621407248939, np.str_('uma'): 0.006578498070221886, np.str_('plot'): 0.008439758770536465, np.str_('humor'): 0.008463866246137621, np.str_('flow'): 0.007899849942231729, np.str_('dolman'): 0.004119344375262881, np.str_('good'): 0.009268527091847464, np.str_('character'): 0.007311609150668485, np.str_('diagnosed'): 0.008732048467456613, np.str_('anyone'): 0.007682906925988289, np.str_('personality'): 0.0057620794597254745, np.str_('loss'): 0.005237169976513541, np.str_('sappy'): 0.0031671454055817714, np.str_('opposite'): 0.001113216196705898, np.str_('such'): 0.008398240852573262, np.str_('am'): 0.006512201482654841, np.str_('reduces'): 0.007037273069780446, np.str_('mean'): 0.005937209075240343, np.str_('father'): 0.0058093006385654235, np.str_('practically'): 0.0053514963602827054, np.str_('me'): 0.004816373650607072, np.str_('likely'): 0.0021952410656682192, np.str_('left'): 0.0033796973177996265, np.str_('beyond'): 0.0005322222321158861, np.str_('abc'): 0.00011789463647557145, np.str_('scripted'): 0.0021191953951363923, np.str_('very'): 0.009847858950493678, np.str_('7'): 0.00641123693102314, np.str_('bravo'): 0.0015372931963339974, np.str_('odd'): 0.009024657389170982, np.str_('due'): 0.008940989494761369, np.str_('still'): 0.007089041155251534, np.str_('indians'): 0.002817072136742546, np.str_('particular'): 0.009107452699111597, np.str_('maybe'): 0.007356155559633405, np.str_('they'): 0.008514474676007926, np.str_('pool'): 0.009951852027089597, np.str_('him'): 0.009411641318478683, np.str_('fine'): 0.004132674516572829, np.str_('only'): 0.006998174073002483, np.str_('gets'): 0.0047618655846825364, np.str_('middle'): 0.0020538135023427627, np.str_('inside'): 0.004506865287609135, np.str_('days'): 0.007966884080839752, np.str_('been'): 0.008373187359298569, np.str_('intrigues'): 0.0024533356727963664, np.str_('have'): 0.006775397109661774, np.str_('able'): 0.0017224203619633357, np.str_('2'): 0.0005984960688549533, np.str_('bad'): 0.009644071968837774, np.str_('sane'): 0.0013637652057221297, np.str_('battle'): 0.00020434011459751153, np.str_('raj'): 0.0057783684478362185, np.str_('poor'): 0.009934774842424669, np.str_('these'): 0.009837567021715916, np.str_('club'): 0.00479994563539257, np.str_('dream'): 0.0025676685582366496, np.str_('least'): 0.006964588172063729, np.str_('photography'): 0.005447896774214541, np.str_('story'): 0.006046580981809009, np.str_('believability'): 0.0019298310669905942, np.str_('today'): 0.007832162849513699, np.str_('sucker'): 0.008093184011173255, np.str_('overacting'): 0.0060873824498770684, np.str_('correct'): 0.003946455062375902, np.str_('sensitive'): 0.002390658511624065, np.str_('essence'): 0.0019853631516895077, np.str_('caricatures'): 0.0018070842547978313, np.str_('will'): 0.0061316000324218595, np.str_('world'): 0.008437595782235567, np.str_('way'): 0.00753751001712118, np.str_('lines'): 0.00014070313133083976, np.str_('stupid'): 0.009368444374177018, np.str_('since'): 0.006028635827783514, np.str_('flimsy'): 0.0028008345861520096, np.str_('francais'): 0.0027528108834812934, np.str_('we'): 0.00458589163967257, np.str_('jerk'): 2.7471108513777274e-05, np.str_('hand'): 0.00848995817324069, np.str_('much'): 0.006958998699907405, np.str_('immoral'): 0.008268048816024028, np.str_('up'): 0.008020094151884075, np.str_('get'): 0.0071458462939018655, np.str_('opportunities'): 0.001629876257760798, np.str_('agent'): 0.009460221409973376, np.str_('basic'): 0.009146697822505375, np.str_('also'): 0.009111811603000206, np.str_('award'): 0.0070371527091773155, np.str_('going'): 0.006128249354702402, np.str_('political'): 0.004713182263855906, np.str_('might'): 0.006269844849391391, np.str_('yes'): 0.008937167298888922, np.str_('line'): 0.00456137179499217, np.str_('valentine'): 0.004207348371493018, np.str_('prescott'): 0.003947735389218135, np.str_('acting'): 0.005044549982502509, np.str_('failed'): 8.066115113754052e-05, np.str_('weren'): 7.619655898672156e-05, np.str_('about'): 0.008307465757409087, np.str_('kid'): 0.0016690199007637142, np.str_('unforgettable'): 0.0013257464253655826, np.str_('barefoot'): 0.0010511985909975872, np.str_('makes'): 0.0022531989070604425, np.str_('fu'): 0.000637066562356642, np.str_('subtitles'): 0.000521031907917784, np.str_('loads'): 0.0004527054332497891, np.str_('brilliant'): 0.00023193767611434047, np.str_('silliest'): 2.1306489501410643e-05, np.str_('plays'): 0.007223320916120991, np.str_('here'): 0.005302703530182005, np.str_('probably'): 0.004079103356453374, np.str_('cop'): 0.003363500880369103, np.str_('jaws'): 0.009718993426805414, np.str_('pretty'): 0.006471397197552598, np.str_('hurry'): 0.008846741702818543, np.str_('based'): 0.005619024038072401, np.str_('alloted'): 0.0043476695593107784, np.str_('every'): 0.00628984537042863, np.str_('why'): 0.007886951425403889, np.str_('worse'): 0.00939603873998908, np.str_('instead'): 0.007579146482451529, np.str_('between'): 0.006305182533384197, np.str_('beasts'): 0.005890100366006997, np.str_('remote'): 0.005871424815142792, np.str_('monster'): 0.002067065545419024, np.str_('listening'): 0.008997225791799013, np.str_('swear'): 0.005542934618363393, np.str_('wearing'): 0.005332513323045726, np.str_('involves'): 0.0025047319918645567, np.str_('sub'): 0.0005028744286884227, np.str_('8'): 0.006375657318418934, np.str_('potboilers'): 0.005331654916606383, np.str_('chipping'): 0.000647091557569238, np.str_('isn'): 0.0074334377799955866, np.str_('best'): 0.005811386503713444, np.str_('thing'): 0.006276654621681002, np.str_('verhoeven'): 0.004912715185360679, np.str_('idiot'): 0.002251991657109193, np.str_('place'): 0.003695250308023342, np.str_('adults'): 0.008312640454825777, np.str_('ve'): 0.0061570145273206036, np.str_('itself'): 0.006319506979491708, np.str_('quinn'): 0.007772794838108643, np.str_('taken'): 0.007351632117031899, np.str_('premise'): 0.006494814924819086, np.str_('ups'): 0.003617790658152527, np.str_('has'): 0.007768778412873344, np.str_('most'): 0.006967789339503596, np.str_('common'): 0.004159943763454677, np.str_('rarely'): 0.004168970055080929, np.str_('dogs'): 0.004100510718299373, np.str_('positives'): 0.0005223977947456954, np.str_('made'): 0.009381427849319193, np.str_('short'): 0.007722126217476632, np.str_('worked'): 0.007074993210224932, np.str_('nice'): 0.0030108836743008745, np.str_('streak'): 0.007062681474437814, np.str_('widescreen'): 0.0024431755764526887, np.str_('explaining'): 0.00925827430201683, np.str_('commit'): 0.007708120200262445, np.str_('our'): 0.007562648255821911, np.str_('own'): 0.004364961182922951, np.str_('perfect'): 0.007321400162847615, np.str_('while'): 0.008826818601646103, np.str_('hurts'): 0.009814324841077629, np.str_('killer'): 0.008545834645123068, np.str_('hey'): 0.0025691120608344496, np.str_('tone'): 0.00879490233286625, np.str_('minutes'): 0.0071864612099269976, np.str_('tilly'): 0.008387164072761879, np.str_('ahead'): 0.007827477911845696, np.str_('presumably'): 0.007702925776410978, np.str_('offensive'): 0.006876036316074859, np.str_('female'): 0.006460627594194962, np.str_('orthodoxy'): 0.006185101039036552, np.str_('anti'): 0.007482747720484559, np.str_('general'): 0.00521137133600978, np.str_('more'): 0.004984323150805776, np.str_('christ'): 0.00036014799366476533, np.str_('1980'): 0.008858340281954261, np.str_('thatcher'): 0.008891992146449782, np.str_('into'): 0.005607106992165847, np.str_('ludicrous'): 0.008440147350346065, np.str_('centre'): 0.004396252355728269, np.str_('points'): 0.002284844043333736, np.str_('pm'): 0.001951912081625997, np.str_('weakness'): 0.0014936718192306402, np.str_('interest'): 0.009878274479638934, np.str_('though'): 0.00914219989094371, np.str_('excellent'): 0.008214261246226744, np.str_('tests'): 0.0038238708291448006, np.str_('once'): 0.0068383185482952255, np.str_('kick'): 0.009937512009926576, np.str_('butt'): 0.007688617010819842, np.str_('bored'): 0.005138123502553393, np.str_('wanting'): 0.004827979281809323, np.str_('perhaps'): 0.003997197787272272, np.str_('clichés'): 0.009783590015919096, np.str_('interesting'): 0.004771450902811055, np.str_('times'): 0.008297665345631124, np.str_('too'): 0.005958192458928234, np.str_('next'): 0.009349269489018385, np.str_('your'): 0.007600021922370929, np.str_('tim'): 0.006715118119335769, np.str_('desire'): 0.0013713378486918885, np.str_('somewhat'): 0.00823593459309119, np.str_('animation'): 0.005880213793472032, np.str_('kung'): 0.004046137501732187, np.str_('jaw'): 0.003045648381946595, np.str_('singing'): 0.007905522788116874, np.str_('divided'): 0.009655323918072466, np.str_('stops'): 0.008478764735323524, np.str_('name'): 0.008828699027250293, np.str_('come'): 0.009423753453542575, np.str_('kind'): 0.008700934440767267, np.str_('astronaut'): 0.004473856485620547, np.str_('rampage'): 0.004327721615772997, np.str_('reporter'): 0.009581834613515016, np.str_('needs'): 0.008262278611211296, np.str_('budget'): 0.007673937056973709, np.str_('low'): 0.007082813318412009, np.str_('robocop'): 0.0058295930000591915, np.str_('tracks'): 0.005347700560756152, np.str_('tracker'): 0.004337054282124564, np.str_('school'): 0.008647330722147958, np.str_('1969'): 0.005891481238336299, np.str_('rounds'): 0.005235400153095887, np.str_('trying'): 0.00905697534293894, np.str_('gore'): 0.0029213549280776687, np.str_('bruno'): 0.002839191501298421, np.str_('bitten'): 0.0012903573512951572, np.str_('somehow'): 0.00787984134896083, np.str_('balloon'): 0.006268391531718996, np.str_('ridiculous'): 0.003005059133469413, np.str_('sure'): 0.008279699494432309, np.str_('appeared'): 0.005737541844836817, np.str_('documentaries'): 0.006978283875825791, np.str_('ll'): 0.007143627504404185, np.str_('power'): 0.004816675094137203, np.str_('eye'): 0.0020326098578482376, np.str_('which'): 0.007120391801897283, np.str_('impressed'): 0.00880650258262511, np.str_('merely'): 0.009034398667378036, np.str_('experienced'): 0.0035986507565548306, np.str_('deeper'): 0.0022675407458705027, np.str_('subsequently'): 0.0016425209931967273, np.str_('convince'): 0.0003792821145587109, np.str_('cardz'): 0.00757688588311704, np.str_('darn'): 0.0070985151227313074, np.str_('0'): 0.006208206902960312, np.str_('musta'): 0.005409888574582542, np.str_('dvd'): 0.005055094609624614, np.str_('figure'): 0.004230612451784747, np.str_('wasn'): 0.007185850168451481, np.str_('support'): 0.0036752812364704767, np.str_('wrong'): 0.007657567745800945, np.str_('involved'): 0.009315019365423309, np.str_('boy'): 0.004899469880342642, np.str_('actually'): 0.007425040717904318, np.str_('sneak'): 0.002256203349527806, np.str_('youngest'): 0.00741805277686499, np.str_('grown'): 0.007081397346192118, np.str_('supposed'): 0.006469390471443322, np.str_('plus'): 0.00872326232223389, np.str_('first'): 0.008295797302044827, np.str_('money'): 0.009036449255995447, np.str_('1954'): 0.004312527256270008, np.str_('treated'): 0.009253985575828644, np.str_('cover'): 0.007489603210801457, np.str_('public'): 0.006925881107266586, np.str_('unfulfilled'): 0.0035597004369344173, np.str_('final'): 0.008873094648607428, np.str_('showing'): 0.004713831911967508, np.str_('met'): 0.004446159041598694, np.str_('happening'): 0.0038304261868102986, np.str_('say'): 0.009527891238742304, np.str_('go'): 0.006744525462064194, np.str_('fifties'): 0.008874322786189123, np.str_('winters'): 0.008575922359735061, np.str_('show'): 0.007395424592381554, np.str_('setting'): 0.005282963277702088, np.str_('ruled'): 0.004705313243959022, np.str_('eighties'): 0.0035563258456803013, np.str_('military'): 0.002011339537261008, np.str_('disturb'): 0.00944081470209055, np.str_('if'): 0.009383549588402849, np.str_('miniature'): 0.007047034297772955, np.str_('talent'): 0.0069453322972187195, np.str_('song'): 0.0026163664494506795, np.str_('villain'): 0.007312271639351752, np.str_('move'): 0.0006446590152729727, np.str_('just'): 0.006280244070239887, np.str_('issue'): 0.008802439527181138, np.str_('valuable'): 0.007809639180584354, np.str_('race'): 0.007610343818495875, np.str_('liked'): 0.002607867211795819, np.str_('abandoned'): 0.00939661644449976, np.str_('trauma'): 0.00787085765038289, np.str_('enthralling'): 0.007160575015590789, np.str_('johnnie'): 0.006073643941582817, np.str_('playing'): 0.00948997910980797, np.str_('whole'): 0.009593467750933263, np.str_('box'): 0.005296405017556386, np.str_('released'): 0.004246703052451765, np.str_('actual'): 0.007821202583749867, np.str_('terrific'): 0.008803091581493254, np.str_('writer'): 0.005154261342112978, np.str_('remember'): 0.004413574709214816, np.str_('clue'): 0.0033180769140566907, np.str_('bar'): 0.0016130068713065128, np.str_('seriously'): 0.009509856195046941, np.str_('need'): 0.008561103218316596, np.str_('rolled'): 0.005185228406851587, np.str_('1988'): 0.002730825381383447, np.str_('felt'): 0.004150431784009277, np.str_('alejandra'): 0.00995551935886431, np.str_('antonio'): 0.009810188227821906, np.str_('winner'): 0.006479286007176881, np.str_('suits'): 0.006414103449597236, np.str_('portrayal'): 0.0016938757570475517, np.str_('graphic'): 0.0006683097542657044, np.str_('pack'): 0.006668669065675376, np.str_('rewritten'): 0.005890249001438464, np.str_('assumes'): 0.004185468232234383, np.str_('happened'): 0.002569197351732711, np.str_('brought'): 0.0065349737330304535, np.str_('4'): 0.004087408254001678, np.str_('scrapes'): 0.0036011039571713834, np.str_('attempt'): 0.0067294075660932215, np.str_('hero'): 0.005872755320543739, np.str_('tramp'): 0.005154609020600788, np.str_('cliché'): 0.004060675612999994, np.str_('lady'): 0.0032693406834531894, np.str_('walked'): 0.008610847696605226, np.str_('try'): 0.00837998807864051, np.str_('saw'): 0.0030826320282940885, np.str_('yourself'): 0.009658090414497045, np.str_('audience'): 0.00880473058880476, np.str_('liner'): 0.008756151852806964, np.str_('obviously'): 0.00750618711245795, np.str_('case'): 0.0019434186718720152, np.str_('nuts'): 0.008449330002188735, np.str_('listen'): 0.0031957291217073126, np.str_('demonicus'): 0.00045934569093319895, np.str_('could'): 0.008384456228701015, np.str_('feeling'): 0.006833986984552358, np.str_('sick'): 0.0024334434769122553, np.str_('my'): 0.001320576837625632, np.str_('wanted'): 0.008503493594642308, np.str_('store'): 0.00621383201878818, np.str_('room'): 0.00842030643781066, np.str_('goodbye'): 0.005087616303192404, np.str_('generation'): 0.0045472904603195115, np.str_('social'): 0.004521486664635085, np.str_('catch'): 0.008703436763912999, np.str_('twists'): 0.007717864367901879, np.str_('dennis'): 0.004058988820465413, np.str_('action'): 0.0021642332739439728, np.str_('take'): 0.005811786295101873, np.str_('30'): 0.006733360868017854, np.str_('oakland'): 0.0012752852298096502, np.str_('via'): 0.0012363036303162948, np.str_('certain'): 0.008332402053215338, np.str_('cinematic'): 0.007391872838663212, np.str_('unfamiliarity'): 0.00230953046102317, np.str_('jurassic'): 0.004843640143728162, np.str_('fi'): 0.007659442923848314, np.str_('treasure'): 0.003487077685239882, np.str_('call'): 0.005773180038247595, np.str_('sound'): 0.005862799597856759, np.str_('during'): 0.00727884759229674, np.str_('beliefs'): 0.00928652920649081, np.str_('swayze'): 0.004072428388318694, np.str_('took'): 0.003253597965257633, np.str_('laugh'): 0.0008821144603990092, np.str_('ok'): 0.008821229033055102, np.str_('believable'): 0.003813508162647357, np.str_('natural'): 0.008199668696114661, np.str_('lemuria'): 0.007886795940109978, np.str_('goddess'): 0.0062493376559026445, np.str_('powers'): 0.005634227692764477, np.str_('loved'): 0.00512629182482397, np.str_('events'): 0.004060754230743218, np.str_('aware'): 0.008040556329947037, np.str_('idea'): 0.0019642381261215044, np.str_('work'): 0.009325074186618052, np.str_('steal'): 0.009865786141987642, np.str_('rather'): 0.008757949821172627, np.str_('long'): 0.001528861698614505, np.str_('passer'): 0.009083802880633582, np.str_('payoff'): 0.0089060394782738, np.str_('book'): 0.008702368255328065, np.str_('york'): 0.006514461084926606, np.str_('begins'): 0.0009302797674603204, np.str_('city'): 0.0006159892232798478, np.str_('portrait'): 0.00971303413116272, np.str_('shot'): 0.008406599702602517, np.str_('perceptively'): 0.006904641773492689, np.str_('lessons'): 0.009958305417318358, np.str_('minimalistically'): 0.0019357485114934747, np.str_('messed'): 0.007339978468495472, np.str_('collision'): 0.007282542946881827, np.str_('cia'): 0.004721122390762068, np.str_('jo'): 0.001885642533547662, np.str_('terrorizes'): 0.0009421795654063925, np.str_('understood'): 0.00917755905581958, np.str_('start'): 0.0011294254264750687, np.str_('given'): 0.008046400778270082, np.str_('well'): 0.006558085800472655, np.str_('buy'): 0.008395166169258075, np.str_('background'): 0.0053457445150673156, np.str_('duo'): 0.002484201060203288, np.str_('juke'): 0.0014080659087302998, np.str_('celebration'): 0.002728380549927434, np.str_('cities'): 0.0020255837751020542, np.str_('find'): 0.009408987200369704, np.str_('nor'): 0.005745715674136932, np.str_('14'): 0.007573592041275018, np.str_('another'): 0.005075391601460616, np.str_('ice'): 6.335663510259983e-05, np.str_('painful'): 0.009151967635933421, np.str_('commented'): 0.007166667092898395, np.str_('grade'): 0.006055023917237889, np.str_('campy'): 0.0017966576500952995, np.str_('confusion'): 0.008818858808846078, np.str_('isolated'): 0.006851836275840569, np.str_('worst'): 0.002293153562275825, np.str_('stays'): 0.003635924241720634, np.str_('capote'): 0.001598978918431174, np.str_('drama'): 0.0014673713573233695, np.str_('competitive'): 0.007412186944687263, np.str_('bunch'): 0.006810411989986575, np.str_('boys'): 0.0065270891685027446, np.str_('group'): 0.006206773022190126, np.str_('hazard'): 0.005811573006939003, np.str_('words'): 0.0031676525887984995, np.str_('those'): 0.0028671448420553008, np.str_('derived'): 0.0010526473708588984, np.str_('hanging'): 0.0040756163234258735, np.str_('reminds'): 0.008820114964060013, np.str_('serendipitous'): 0.00831399398610685, np.str_('witch'): 0.009395239435940825, np.str_('black'): 0.005902076840395825, np.str_('bleeding'): 0.001907851478925482, np.str_('wouldn'): 0.009394406523047131, np.str_('andreas'): 0.004239050827000484, np.str_('epidemic'): 0.0028404375558877385, np.str_('deserves'): 0.0064475767378023244, np.str_('years'): 0.006262257271544679, np.str_('favorites'): 0.005269578776851687, np.str_('hollywood'): 0.0038407612875254542, np.str_('engaged'): 0.0043612874705478335, np.str_('examples'): 0.0010137246454316174, np.str_('air'): 0.00989477185067191, np.str_('view'): 0.0075053543729237775, np.str_('little'): 0.007320725750919096, np.str_('overwhelmed'): 0.005250197445693733, np.str_('exactly'): 0.003899655170051946, np.str_('gary'): 0.002503104772869914, np.str_('army'): 0.002019026303404473, np.str_('l'): 0.001760654157289329, np.str_('south'): 0.0017538732174552291, np.str_('q'): 0.0010308945953954448, np.str_('laughable'): 0.0009496917565118171, np.str_('wastes'): 0.0008842205478086526, np.str_('towelheads'): 0.0008044015752753421, np.str_('complained'): 0.008069433381561715, np.str_('balance'): 0.00782899408068565, np.str_('mess'): 0.007740639617455758, np.str_('napoleon'): 0.008844046032229609, np.str_('effects'): 0.007035130163822815, np.str_('1'): 0.008831376124009452, np.str_('popular'): 0.0068505512974817604, np.str_('sequels'): 0.005908073111303675, np.str_('guys'): 0.005103220723378031, np.str_('help'): 0.008281220367348026, np.str_('considered'): 0.007935615417486584, np.str_('goddard'): 0.007577680667886608, np.str_('young'): 0.005973844247800774, np.str_('sidewalk'): 0.003531674482250493, np.str_('bed'): 0.00890511908150227, np.str_('english'): 0.008210653495653754, np.str_('wife'): 0.007247390667553307, np.str_('reduced'): 0.00367643719385602, np.str_('died'): 0.0018994942314199226, np.str_('publicised'): 0.008673837359097124, np.str_('worth'): 0.008336861550075523, np.str_('watched'): 0.0012662066433961482, np.str_('mainly'): 0.0011474630072659446, np.str_('hence'): 0.0005406397369575602, np.str_('improvement'): 0.005377401161362522, np.str_('reactions'): 0.005225015674150961, np.str_('must'): 0.004320783266576587, np.str_('choco'): 0.0012088143037441918, np.str_('draw'): 0.009970893107041757, np.str_('considering'): 0.007936922500914288, np.str_('hate'): 0.005899948690387933, np.str_('longer'): 0.005318552979721387, np.str_('being'): 0.004867140564247595, np.str_('ten'): 0.0035653006510589285, np.str_('grotesque'): 0.0012387900069597152, np.str_('performers'): 0.00151177827983657, np.str_('mind'): 0.0010810996318721966, np.str_('rukh'): 0.009994731910302979, np.str_('smooch'): 0.00623620368300853, np.str_('appears'): 0.0038253333637126223, np.str_('cant'): 0.0034104833508034364, np.str_('context'): 0.007935659697028, np.str_('pilot'): 0.0065711259212993, np.str_('thriller'): 0.0008252397352774541, np.str_('davis'): 0.00031847064201647276, np.str_('paul'): 0.0002758353027940644, np.str_('sympathies'): 0.009104164620124068, np.str_('shots'): 0.006687623556072195, np.str_('think'): 0.00952503963127428, np.str_('bouncy'): 0.005676260273707865, np.str_('nature'): 0.0016422188219733188, np.str_('director'): 0.00013275228568981217, np.str_('couple'): 0.007913262499360954, np.str_('jody'): 0.006691932527263998, np.str_('fanzine'): 0.006365660543022271, np.str_('hundred'): 0.005739304259524585, np.str_('forgotten'): 0.005238116186037517, np.str_('published'): 0.003128472017733046, np.str_('obscure'): 0.001939661453747032, np.str_('challenges'): 0.0074823233494033725, np.str_('starting'): 0.007088528994247871, np.str_('silly'): 0.009813120912048251, np.str_('emotions'): 0.004799984517086721, np.str_('clips'): 0.003994116909371113, np.str_('exploit'): 0.003921028279295509, np.str_('angry'): 0.006842940205538245, np.str_('living'): 0.005255092956153177, np.str_('5'): 0.004417243044468195, np.str_('door'): 0.008938765947583536, np.str_('somebody'): 0.008714604540069174, np.str_('fans'): 0.008777533947500221, np.str_('ghosts'): 0.008343139949282059, np.str_('funds'): 0.007833120992850539, np.str_('works'): 0.006180639890600833, np.str_('temple'): 0.0008672086274354426, np.str_('atta'): 0.007924240324722397, np.str_('lead'): 0.007283974950765001, np.str_('tries'): 0.005213788216474377, np.str_('introduces'): 0.0031296134058728707, np.str_('intensity'): 0.008109292508934897, np.str_('corner'): 0.00800159388119508, np.str_('digs'): 0.0073723613557511915, np.str_('set'): 0.00664864456564735, np.str_('choice'): 0.009229164836058937, np.str_('live'): 0.006805292958218061, np.str_('daughter'): 0.006522961500460154, np.str_('comment'): 0.009970207446330011, np.str_('sooraj'): 0.007203992910142117, np.str_('happens'): 0.0008913669004400573, np.str_('programs'): 0.00937638229732741, np.str_('sci'): 0.004667976131479823, np.str_('stargate'): 0.0024894988490961364, np.str_('become'): 0.0007527884130293349, np.str_('spectacular'): 0.0002874760281654147, np.str_('extremely'): 0.006872598769769021, np.str_('rottentomatoes'): 0.006828414389138674, np.str_('etc'): 0.00597481612514766, np.str_('water'): 0.0010924689271247165, np.str_('battles'): 0.008585749154132781, np.str_('alas'): 0.007006996153662122, np.str_('contains'): 0.0034039360413036885, np.str_('title'): 0.002391344396207145, np.str_('master'): 0.0020868643494769486, np.str_('grabbed'): 0.0017401310911350648, np.str_('wait'): 0.006735418592218919, np.str_('tags'): 0.0025676457769837633, np.str_('special'): 0.0018519488586251204, np.str_('columbo'): 0.008939059186695084, np.str_('peter'): 0.0039281682288639895, np.str_('solves'): 0.0038919428499602222, np.str_('ruth'): 0.0021436510119525265, np.str_('flicks'): 0.0016947863639059214, np.str_('latest'): 0.0010096722253831731, np.str_('brow'): 0.009706406847195533, np.str_('actor'): 0.006804767077222229, np.str_('billy'): 0.00679324295250206, np.str_('spot'): 0.006390329241525933, np.str_('autograph'): 0.004655760522141714, np.str_('heavy'): 0.007000909754032796, np.str_('minus'): 0.0069015759084966, np.str_('king'): 0.0064197888845349315, np.str_('gallic'): 0.004345061864262964, np.str_('virtuous'): 0.004028922814664422, np.str_('let'): 0.00829132770623506, np.str_('empathize'): 0.007991201656980482, np.str_('dull'): 0.003393899925129503, np.str_('largest'): 0.009946658754206153, np.str_('crooked'): 0.008957940119885132, np.str_('launching'): 0.0063286894381861395, np.str_('capt'): 0.002677499737355569, np.str_('obvious'): 0.00841145343147823, np.str_('talking'): 0.0065736758720804185, np.str_('somewhere'): 0.005895428066265576, np.str_('used'): 0.003720752382092589, np.str_('theater'): 0.00055391365593182, np.str_('eastern'): 0.009870943830495587, np.str_('soldiers'): 0.008125033712326434, np.str_('removing'): 0.008031624266251218, np.str_('exists'): 0.005038891592199507, np.str_('rising'): 0.002759393709260071, np.str_('rose'): 0.0002271964258605524, np.str_('husband'): 0.002885920163576028, np.str_('realize'): 0.0001556231450727961, np.str_('everyone'): 0.009772200613961833, np.str_('urban'): 0.005334628490394869, np.str_('taylor'): 0.008530204604438011, np.str_('slaughter'): 0.007104079529680093, np.str_('exterior'): 0.00620319058719243, np.str_('granger'): 0.0034427282575776744, np.str_('naivete'): 0.002741074305819769, np.str_('prevent'): 0.003753342734242641, np.str_('confrontations'): 0.0018589921090111274, np.str_('reason'): 0.0016365973161653127, np.str_('scheduled'): 0.0011413443627987176, np.str_('rubbish'): 0.005766005182924201, np.str_('preview'): 0.009490843028082781, np.str_('hilarious'): 0.004252070738766151, np.str_('captures'): 0.008985154158779205, np.str_('early'): 0.005671090049080901, np.str_('address'): 0.0017337472731624867, np.str_('camera'): 0.006660815255248164, np.str_('overwhelming'): 0.0006934455939322455, np.str_('betrays'): 0.005945660065733115, np.str_('except'): 0.002830559421560853, np.str_('horror'): 0.00626896270487848, np.str_('adolescents'): 0.006652601963900159, np.str_('whether'): 0.009324185586503136, np.str_('dialogues'): 0.007900723054414048, np.str_('clockwork'): 0.004300513315945862, np.str_('solo'): 0.008472135276778219, np.str_('rocks'): 0.0021893001404329235, np.str_('hamish'): 0.009892401961879047, np.str_('beaton'): 0.008945889835318011, np.str_('written'): 0.0072731710865889185, np.str_('broadcast'): 0.0018637162576569017, np.str_('lame'): 0.007828887422711747, np.str_('aimed'): 0.007734682883931374, np.str_('cinematography'): 0.006626840089744199, np.str_('sorely'): 0.0050344118442470194, np.str_('missed'): 0.003832953576379496, np.str_('handed'): 0.009918804265683995, np.str_('got'): 0.004213969767909134, np.str_('underrated'): 0.006512363469447042, np.str_('proud'): 0.005404513787881149, np.str_('bizarre'): 0.005063164798975021, np.str_('basis'): 0.0061769714606810236, np.str_('religious'): 0.006139592574907706, np.str_('outs'): 0.004665240676152576, np.str_('cool'): 0.00612843556655367, np.str_('looked'): 0.002167482134046575, np.str_('pavement'): 0.0008965766528824934, np.str_('under'): 0.007400720818532605, np.str_('effortlessly'): 0.004349368927321534}\n",
      "No cached classifier found. Training a new one...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\migue\\miniconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.4112 - loss: 0.7683 - val_accuracy: 0.6500 - val_loss: 0.6812\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4937 - loss: 0.7458 - val_accuracy: 0.6500 - val_loss: 0.6837\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4695 - loss: 0.7390 - val_accuracy: 0.6500 - val_loss: 0.6866\n",
      "Cached classifier saved as cached_classifier_ns200_mf474_sw_filtered_NN_classifier_seed0.pkl\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Results => {'num_samples': 200, 'max_features': 15, 'stopwords': True, 'lime_num_samples': 30, 'local_accuracy': np.float64(0.015), 'global_acc': np.float64(0.7), 'global_acc_filtered': np.float64(0.65), 'num_unf_words': 1306, 'num_filt_words': 334}\n",
      "\n",
      "All done! Saved results to 'results_expanded_flips.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    # Parameter grid to systematically vary certain settings\n",
    "    param_grid = {\n",
    "        \"num_samples\": [200],\n",
    "        \"max_features\": [15],\n",
    "        \"stopwords_option\": [True],\n",
    "        \"lime_num_samples\": [30],\n",
    "        \"stop_words\": [['english']],\n",
    "           \n",
    "    }\n",
    "\n",
    "    combos = list(itertools.product(*param_grid.values()))\n",
    "    all_results = []\n",
    "\n",
    "    for combo in combos:\n",
    "        (num_samples_, max_features_, stopwords_, lime_samps_, stop_words_) = combo\n",
    "        \n",
    "        print(\"\\n==================================\")\n",
    "        print(f\"Running experiment with: \"\n",
    "              f\"num_samples={num_samples_}, \"\n",
    "              f\"max_features={max_features_}, \"\n",
    "              f\"stopwords={stopwords_}, \"\n",
    "              f\"lime_num_samples={lime_samps_}, \"\n",
    "              f\"stop_words={stop_words_},\")\n",
    "        \n",
    "        res = run_experiment(\n",
    "            num_samples=num_samples_,\n",
    "            max_features=max_features_,\n",
    "            stopwords_option=stopwords_,\n",
    "            lime_num_samples=lime_samps_,\n",
    "            stop_words=stop_words_,\n",
    "        )\n",
    "        res_row = {\n",
    "            \"num_samples\": num_samples_,\n",
    "            \"max_features\": max_features_,\n",
    "            \"stopwords\": stopwords_,\n",
    "            \"lime_num_samples\": lime_samps_,\n",
    "            \"local_accuracy\": res[\"local_accuracy\"],\n",
    "            \"global_acc\": res[\"global_acc\"],\n",
    "            \"global_acc_filtered\": res[\"global_acc_filtered\"],\n",
    "            \"num_unf_words\": res[\"num_unf_words\"],\n",
    "            \"num_filt_words\": res[\"num_filt_words\"],\n",
    "        }\n",
    "        print(\"Results =>\", res_row)\n",
    "        all_results.append(res_row)\n",
    "\n",
    "    # Save results to CSV\n",
    "    df = pd.DataFrame(all_results)\n",
    "    df.to_csv(\"results_expanded_flips.csv\", index=False)\n",
    "    print(\"\\nAll done! Saved results to 'results_expanded_flips.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bell_inequality)",
   "language": "python",
   "name": "bell_inequality"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
